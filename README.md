# Credit Risk Prediction using XGBoost, SHAP, and LIME

This project predicts the likelihood of a loan applicant defaulting using machine learning techniques.  
The model is built using **XGBoost**, and interpretability is provided using **SHAP** and **LIME**.

The project follows a complete ML workflow including:
- Data cleaning  
- Feature engineering  
- Model training  
- Model evaluation  
- Model interpretability (Global + Local)  
- Case study analysis  
- Exported plots and parameters  

---

## ğŸ“‚ Project Structure

CreditRiskProject/
â”œâ”€â”€ notebook.ipynb
â”œâ”€â”€ credit_risk_dataset.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ report.md
â”œâ”€â”€ model_parameters.txt
â”œâ”€â”€ plots/
â”‚ â”œâ”€â”€ roc_curve.png
â”‚ â”œâ”€â”€ confusion_matrix.png
â”‚ â”œâ”€â”€ shap_summary.png
â”‚ â”œâ”€â”€ shap_bar.png
â”‚ â”œâ”€â”€ lime_high_risk.png
â”‚ â”œâ”€â”€ lime_low_risk.png
â”‚ â”œâ”€â”€ lime_borderline.png
â”‚ â”œâ”€â”€ shap_force_high_risk.png
â”‚ â”œâ”€â”€ shap_force_low_risk.png
â”‚ â”œâ”€â”€ shap_force_borderline.png

yaml
Copy code

---

## ğŸš€ How to Run the Project

### **1. Install dependencies**
pip install -r requirements.txt

yaml
Copy code

### **2. Open the notebook**
Run the `notebook.ipynb` in Google Colab or Jupyter Notebook.

---

## ğŸ§¹ Data Preprocessing

- Missing values were filled using numerical medians.
- Categorical values were encoded using `LabelEncoder`.
- Two interaction features were created:
  - `income_to_loan_ratio`
  - `credit_age_interaction`

---

## ğŸ¤– Model Used â€” XGBoost

Hyperparameters used:

n_estimators = 400
learning_rate = 0.05
max_depth = 5
subsample = 0.8
colsample_bytree = 0.8
eval_metric = "logloss"

yaml
Copy code

These parameters were selected for stability and generalization on credit-risk datasets.

---

## ğŸ“Š Model Evaluation

- **ROC-AUC Score:** High (value in notebook)  
- **Confusion Matrix:** Indicates model performance on positive vs negative classes  
- **Classification Report:** Includes precision, recall, F1-score  

All plots are saved in the `/plots` directory.

---

## ğŸ” Model Interpretability

### **1. SHAP (Global + Local)**  
- Global feature importance (summary + bar plots)  
- Local SHAP force plots for:
  - High-risk case
  - Low-risk case
  - Borderline case  

### **2. LIME (Local)**  
Explains predictions of:
- High-risk applicant  
- Low-risk applicant  
- Borderline applicant  

---

## ğŸ“ Case Studies Included

Three prediction cases were selected:
- **High-Risk Case** (Model says â€œHigh chance of defaultâ€)  
- **Low-Risk Case** (Model says â€œSafe customerâ€)  
- **Borderline Case** (Probability â‰ˆ 50%)  

Both SHAP and LIME are used to explain each decision.

---

## ğŸ“¦ Model Parameters Saved

`model_parameters.txt` contains the dump of XGBoostâ€™s hyperparameters for test evaluation.

---

## ğŸ§¾ Report

A full project report is included in `report.md`.

---

## âœ¨ Summary

This project demonstrates:
- End-to-end credit-risk model development  
- Strong evaluation metrics  
- Explainability using SHAP + LIME  
- Clean GitHub-ready structure  

Perfect for data science tests, ML job tasks, or academic submissions.

---

## ğŸ‘¨â€ğŸ’» Author

Created as part of a machine learning evaluation task.  
Prepared using **Python, XGBoost, SHAP, LIME, Google Colab, and GitHub**.
